# Session: Domain Entity & Capability Modelling ‚Äî 2026-02-21 / 2026-02-22

## Overview

Two-day working session focused on defining the domain model for DobONoMoDo. All work was conducted via Socratic interview using `pm.entity.agent` and `pm.capability.agent`. Each entity and capability was written to `docs/entities/` and `docs/capabilities/` respectively.

---

## Entities Defined

### Dataset (`docs/entities/dataset.md`)
- A **pure logical contract** ‚Äî schema only, no location information.
- Consists of a `main_table` + zero or more `lookups` (joined tables or nested Datasets).
- Each `TableRef` carries an explicit schema (`columns: List<ColumnDef>`) with name, type, nullable.
- Column types: `string | integer | decimal | boolean | date | timestamp`.
- Optional `resolver_id` override per Dataset; when absent, system default Resolver is used.
- `natural_key_columns`: user-defined business key, preserved alongside system `_row_id`.
- Row metadata system columns (all `_` prefixed, injected at runtime):
  - `_row_id` (UUID v7), `_source_dataset_id`, `_source_table`
  - `_created_by_project_id`, `_created_by_run_id`, `_created_at`, `_updated_at`
  - `_deleted` (boolean, default false ‚Äî set by `delete` operation)
  - `_period` (Period identifier string, non-bitemporal tables)
  - `_labels` (mutable Map<String,String>)
- **Key decision**: Location (DataSource, path, connection) removed from Dataset entirely. Physical location is the Resolver's concern ‚Äî enabling transparent migration between storage backends across Periods.

### Bitemporal Dataset (`docs/entities/bitemporal-dataset.md`)
- Subtype of Dataset; enabled per-table via `bitemporal: true` flag on `TableRef`.
- Adds two temporal axes:
  - **Period axis**: `_period_from` / `_period_to` (Period identifier strings) ‚Äî replaces `_period`
  - **Valid axis**: `_valid_from` / `_valid_to` (Dates; NULL = currently valid)
- System time handled by existing `_created_at` / `_updated_at` ‚Äî no separate system columns.
- Update pattern: close old row (`_valid_to = day before correction`), insert new row (`_valid_from = correction date`, `_valid_to = NULL`). Each version gets a different `_row_id`.

### Project (`docs/entities/project.md`)
- Reusable, ordered computation recipe applied to an input Dataset.
- Attributes: `input_dataset_id`, `input_dataset_version` (pinned at activation), `materialization` (`eager | runtime`), `operations`, `selectors`.
- **`selectors`**: `Map<String, Expression>` ‚Äî named reusable row filters scoped to the Project. Referenced in operations as `{{NAME}}`.
- Status lifecycle: `draft ‚Üí active ‚Üí inactive`; `conflict` triggered by breaking Dataset changes.
- **Conflict model**: breaking change (column removed/renamed/type-changed) ‚Üí `conflict` status + `ConflictReport`. Resolution: `adapted` (update ops + advance Dataset version) or `pinned` (reject change).
- Dataset version pinned at activation; impact analysis on new Dataset versions.

### Operation (`docs/entities/operation.md`)
- A single typed unit of work within a Project, executed in `seq` order.
- Attributes: `id`, `seq`, `name`, `description`, `type`, `selector` (Expression string), `arguments`.
- `selector` is a plain boolean Expression string; named selectors referenced as `{{NAME}}`.
- **5 fixed types**:
  - **`update`**: modify/add columns. Optional `joins: List<RuntimeJoin>` makes external columns available under an alias for use in assignment expressions. Every assignment is `column + expression`.
  - **`aggregate`**: appends new summary rows (does NOT replace existing rows). Groups by columns, computes aggregate expressions.
  - **`append`**: brings rows from another Dataset; optional pre-aggregation. Incoming cols ‚äÜ working dataset cols; missing cols ‚Üí NULL.
  - **`delete`**: soft-delete ‚Äî sets `_deleted = true`. Deleted rows auto-excluded from all downstream ops.
  - **`output`**: only IO operation; writes a projection (`selector` + optional `columns` list) to a destination (`TableRef`). `include_deleted` flag (default false). Optional `register_as_dataset` to publish output as a named Dataset.
- `seq` reorderable while Project is `draft`; reordering on `active` Project ‚Üí new Project version.
- **Pipeline is strictly linear** ‚Äî downstream ops reference upstream results via column values/labels.

### Expression (`docs/entities/expression.md`)
- Inline, composable formula embedded inside Operation parameters. Not stored independently.
- **Syntax**: Excel-style function calls + infix arithmetic/comparison/logical operators.
- **Column references**: `logical_table_name.column_name`.
- **NULL propagation**: explicit (SQL-style). Use `ISNULL()` / `COALESCE()` to handle.
- **5 categories**: boolean/conditional (`IF`, `AND`, `OR`, `ISNULL`, `COALESCE`), arithmetic (`ABS`, `ROUND`, `FLOOR`, `CEIL`, `MOD`), string (`CONCAT`, `UPPER`, `LOWER`, `TRIM`, `LEFT`, `RIGHT`, `LEN`, `CONTAINS`, `REPLACE`), date/time (`DATE`, `TODAY`, `YEAR`, `MONTH`, `DAY`, `DATEDIFF`, `DATEADD`), aggregate (`SUM`, `COUNT`, `COUNT_ALL`, `AVG`, `MIN_AGG`, `MAX_AGG`).
- Aggregate functions valid only inside `aggregate` / `append-with-aggregation` operations ‚Äî compile error otherwise.
- `TODAY()` resolves to Run's `started_at` ‚Äî not re-evaluated live (reproducibility).
- Type-checking at Project activation (draft ‚Üí active); expression errors block activation.

### Period (`docs/entities/period.md`)
- User-defined time interval (fiscal month, quarter, etc.) with arbitrary-depth rollup hierarchy.
- Status: `open ‚Üí closed ‚Üí locked` (one-directional).
- Belongs to a Calendar. A Run is tied to one or more Periods.

### Calendar (`docs/entities/calendar.md`)
- Defines a hierarchy of time levels via `LevelDef` + `DateRule` + `identifier_pattern` tokens.
- Gregorian default; multiple Calendars per deployment.
- `CalendarMapping` for cross-Calendar Period conversions.

### CalendarMapping (`docs/entities/calendarmapping.md`)
- Directional (A‚ÜíB and B‚ÜíA are separate entities), versioned Period-to-Period mappings.
- Runs record CalendarMapping `id` + `version` for cross-calendar reproducibility.

### Run (`docs/entities/run.md`)
- Execution instance of a Project for a given Period.
- Captures a full immutable `ProjectSnapshot` at creation (input Dataset id+version, operations, selectors).
- Status: `queued ‚Üí running ‚Üí completed | failed | cancelled`.
- `last_completed_operation` enables resume from failure.
- Partial output preserved on failure.

### DataSource (`docs/entities/datasource.md`)
- Named, reusable connection definitions (database, parquet, csv, api).
- `credential_ref`: lookup key only (e.g., `vault://...`). Never stored inline.
- Status: `active | disabled`.
- **Note**: DataSource is no longer referenced from Dataset directly ‚Äî it is now part of Resolver configuration.

---

## Capabilities Defined

### Execute Project Calculation (`docs/capabilities/execute-project-calculation.md`)
- Core execution capability: given an active Project + Period, execute all Operations in sequence.
- Triggers: manual user action OR Scheduler entity.
- Outputs: Run record + output writes + optionally registered projection Datasets.
- Preconditions: Project `active`, Period exists, no concurrent Run for same Project+Period.
- Failure: partial output kept as-is; resumable from `last_completed_operation + 1`.
- Concurrent run conflict (same Project+Period) ‚Üí rejected immediately.

### Resolve Dataset (`docs/capabilities/resolve-dataset.md`)
- Given a Dataset + Period, invokes the configured Resolver to produce a `ResolutionResult`.
- `ResolutionResult`: `{ handle: DataHandle, status: resolved|empty|error, diagnostics }`.
- `DataHandle` is implementation-specific (Pandas DataFrame, DuckDB view, etc.).
- Resolver validates loaded data against Dataset's declared schema.
- Always returns a result envelope ‚Äî never throws. Caller decides if `empty` is fatal.
- Default Resolver system-wide; overridable per-Dataset via `resolver_id`.
- **Key decision**: Dataset has no location information ‚Äî Resolver owns all physical location logic, enabling transparent migration between storage backends (e.g., CSV 2021-2025, Parquet S3 2025+).

### Trace Run Execution (`docs/capabilities/trace-run-execution.md`)
- Passive audit log: engine writes `TraceRecord` for every changed row at each Operation step.
- **Storage**: diffs only (changed columns). Full row state reconstructed at read time by replaying diffs forward.
- **Change types**: `created` (aggregate/append ‚Äî after only), `updated` (before+after diff), `deleted` (before only). `output` not traced.
- **Query**: by `run_id + _row_id` ‚Üí full step-by-step history or state at a specific step.
- Retention tied to Run lifetime.
- `TraceWriteFailure` is fatal ‚Äî Operation fails, Run ‚Üí `failed`.

---

## Key Architectural Decisions

| Decision | Rationale |
|---|---|
| Dataset is schema-only (no location) | Enables transparent migration between storage backends per Period; legacy environments supported via custom Resolvers without changing Dataset definitions |
| Pluggable Resolver with default + per-Dataset override | Supports both greenfield (default Resolver) and legacy environments (custom naming schemes, different versioning) behind a uniform interface |
| Resolver returns DataHandle, not coordinates | Decouples the engine from storage technology; same computation logic works across Pandas, DuckDB, etc. |
| Resolver validates schema, returns envelope | Schema validation responsibility on the Resolver (it has both schema + data); caller decides if empty/error is acceptable |
| Operations are linearly sequenced | Simplicity; downstream ops reference upstream results via column values and `_labels`, not named step outputs |
| `delete` is soft | `_deleted` flag preserved; resumable pipeline; `output` can include deleted rows via `include_deleted: true` |
| `aggregate` appends, not replaces | Rollup rows co-exist with detail rows in the working dataset |
| Named selectors via `{{NAME}}` interpolation | Simpler DSL; selector is always a plain expression string; no special wrapper object |
| Trace stores diffs, reconstructs on read | Storage efficiency; full state at any step available without redundant full-row snapshots |
| Cross-run comparison deferred | Would require `natural_key_values` on TraceRecords for cross-run row correlation; accepted as future requirement |

---

## Gap Analysis (as of session end)

### üî¥ Blocking ‚Äî needed before a running engine can be built

1. **Resolver entity** ‚Äî `resolve-dataset.md` depends on it; no `resolver.md` exists yet. Interface contract, configuration, default vs. per-Dataset override registration undefined.
2. **Period filter mechanism** ‚Äî How does the engine scope Dataset rows to a Period? (OQ-003 in `execute-project-calculation.md`). Unresolved.
3. **Activate Project capability** ‚Äî `draft ‚Üí active` triggers expression compilation, type-checking, selector validation, Dataset version pinning. No capability doc.
4. **RuntimeJoin resolution** ‚Äî `update` operations reference external tables via `RuntimeJoin`. Whether the Resolver handles these or a separate mechanism is undefined.

### üü° Important but not blocking for first build

5. **Resume Run capability** ‚Äî Implied by `execute-project-calculation.md` and Run entity but no formal capability doc.
6. **Detect Dataset Conflict capability** ‚Äî Project entity describes the conflict model; no capability doc for detection mechanics.
7. **Register Output as Dataset** ‚Äî `output` operation's `register_as_dataset` is described but no capability defines the mechanics.

### üü¢ Out of scope for v1 engine

8. **Scheduler entity** ‚Äî Manual triggering works; Scheduler is a dependency, not core engine logic.
9. **User/Auth** ‚Äî Infrastructure concern; not computation logic.

---

## Files Created / Modified This Session

### New files
- `docs/entities/expression.md`
- `docs/entities/operation.md`
- `docs/capabilities/execute-project-calculation.md`
- `docs/capabilities/resolve-dataset.md`
- `docs/capabilities/trace-run-execution.md`
- `docs/discussion/2026-02-21-session.md` ‚Üê this file

### Modified files
- `docs/entities/dataset.md` ‚Äî Major rewrite: removed all location fields; added `ColumnDef`, `resolver_id`; updated BR-010/011; rewrote YAML schema and example
- `docs/entities/project.md` ‚Äî Added `selectors: Map<String, Expression>` attribute + YAML schema
- `docs/entities/operation.md` ‚Äî Multiple passes:
  - Restructured `update` to separate `joins` (list) from `assignments` (always expression-based)
  - Added `columns` + `register_as_dataset` to `output`
  - Simplified `selector` from `SelectorRef` object to plain Expression string with `{{NAME}}` convention
  - Removed `SelectorRef` embedded structure
- `docs/entities/dataset.md` ‚Äî Added `_deleted` system column (BR-019)
